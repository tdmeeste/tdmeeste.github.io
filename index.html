---
layout: default
---


		<!-- Banner -->
			<section id="banner">
				<div class="inner">
					<h2>Thomas Demeester</h2>
					<p>Natural Language Processing, Deep Learning & AI</p>
					<ul class="actions">
						<li><a href="index.html" class="button big alt">Home</a></li>
						<li><a href="publications.html" class="button big alt">Publications</a></li>
						<li><a href="contact.html" class="button big alt">Contact</a></li>
					</ul>
					<ul class="actions">
						<li><a href="#bio" class="button alt">Bio</a></li>
						<li><a href="#news" class="button alt">News</a></li>
						<li><a href="#recent" class="button alt">Recent work</a></li>
					</ul>
				</div>
			</section>


		<!-- Short bio -->
			<section id="bio" class="wrapper style1">
                <div class="container">
                    <header class="major">
                        <h2>Short bio & research interests</h2>
                    </header>
					<div class="row">
						<div class="3u">
							<section>
								<a href="#" class="image left"><img src="images/thomas.jpg" alt="" width="150"/></a>
							</section>
						</div>
						<div class="8u">
							<section>
                                <!--current research-->
								<p>
                                    I'm a postdoctoral researcher at the <a href="https://www.ugent.be/ea/idlab/en">Internet Technology and Data Science Lab (IDLab)</a>, Ghent University, Belgium. I'm co-leading the Text-to-Knowledge research cluster with prof. <a href="http://users.atlantis.ugent.be/cdvelder/">Chris Develder</a>, where we work on natural language processing in general, with focus on information extraction for applications in the media and medical domain.</p>
                                <p>
                                    Besides sequence modeling with neural networks, I'm particularly interested in injecting background knowledge in neural network models. During a recent research visit at the <a href="http://mr.cs.ucl.ac.uk/">Machine Reading Lab</a> at the <a href="https://www.ucl.ac.uk/">University College London</a>, I worked on <a href="https://arxiv.org/abs/1606.08359">injecting first-order logic into neural link prediction models</a>. Together with the <a href="https://dtai.cs.kuleuven.be/">DTAI</a> research group at <a href="https://www.kuleuven.be/english/">KULeuven</a>, I am currently working on the <a href="https://arxiv.org/abs/1805.10872">combination of neural networks and probabilistic logic programs</a>. These research topics fit within my general interest in joining deep learning models with classical systems for various applications. My latest research focuses on the combination of my current expertise in deep learning with previous experience in solving sets of differential equations.
                                </p>
                                <p>
                                    In 2005, I received my M.Sc. degree in electrical engineering at Ghent University, after finishing my final year and master thesis at <a href="https://www.ethz.ch/en.html">ETH Zurich</a>, Switzerland, where I worked as a student assistent. In 2009, funded by a grant from the <a href="http://www.fwo.be/en/">Research Foundation - Flanders</a> (FWO), I obtained my Ph.D. at the Ghent University Department of Information Technology, under the supervision of prof. Daniel De Zutter, in the area of computational electromagnetics.
                                    Shortly afterwards, I got involved in research on Information Retrieval, in collaboration with the <a href="https://www.utwente.nl/en/eemcs/db/">Database Group</a> at the <a href="https://www.utwente.nl/en/">University of Twente</a> in The Netherlands.
                                </p>
							</section>
							<!--<hr />-->
						</div>
					</div>
				</div>
			</section>

		<!-- News -->
			<section id="news" class="wrapper style2">
				<header class="major">
					<h2>Latest News</h2>
					<!--<p>Amet nisi nunc lorem accumsan</p>-->
				</header>
				<div class="container">
					<div class="column">
						<div class="0u">
                            <table style="">

                                <tr>
                                    <td>09/05/2018</td>
                                    <td><i>"DeepProbLog: Neural Probabilistic Logic Programming"</i> accepted as spotlight presentation at <u>NIPS 2018</u>. <a href="https://arxiv.org/pdf/1805.10872">[pdf]</a></td>
                                </tr>
                                <tr>
                                    <td>08/10/2018</td>
                                    <td><i>"Explaining Character-Aware Neural Networks for Word-Level Prediction: Do They Discover Linguistic Rules?"</i> accepted for <u>EMNLP 2018</u>. <a href="https://arxiv.org/pdf/1808.09551.pdf">[pdf]</a> <a href="https://github.com/FredericGodin/ContextualDecomposition-NLP">[code]</a></td>
                                </tr>
                                <tr>
                                    <td>08/10/2018</td>
                                    <td><i>"Adversarial training for multi-context joint entity and relation extraction"</i> accepted for <u>EMNLP 2018</u>. <a href="https://arxiv.org/pdf/1808.06876.pdf">[pdf]</a> <a href="https://github.com/bekou/multihead_joint_entity_relation_extraction">[code]</a></td>
                                </tr>
                                <tr>
                                    <td>07/27/2018</td>
                                    <td><i>"Predefined Sparseness in Recurrent Sequence Models"</i> accepted for <u>CoNLL 2018</u>. <a href="https://arxiv.org/pdf/1808.08720.pdf">[pdf]</a> <a href="https://github.com/tdmeeste/SparseSeqModels">[code]</a> </td>
                                </tr>
                                <tr>
                                    <td>07/13/2018</td>
                                    <td><i>"Joint entity recognition and relation extraction as a multi-head selection problem"</i> accepted by <u>Expert Systems With Applications</u>. <a href="https://arxiv.org/pdf/1804.07847v1.pdf">[pdf]</a> <a href="https://github.com/bekou/multihead_joint_entity_relation_extraction">[code]</a></td>
                                </tr>
                            </table>
						</div>
					</div>
				</div>
			</section>



		<!-- Recent work -->
			<section id="recent" class="wrapper style1">
				<header class="major">
					<h2>Recent Work</h2>
					<!--<p>Tempus adipiscing commodo ut aliquam blandit</p>-->
				</header>
				<div class="container">
					<div class="row">
						<div class="4u">
							<section class="special box">
                                <div class="image rounded">
                                    <img src="images/recent_work/snapshot_sparseRNN.png" alt="" />
                                </div>
                                <h4>Predefined Sparseness <br/>in recurrent sequence models</h4>
                                <p>CoNLL 2018</p>
								<p><a href="https://arxiv.org/pdf/1808.08720.pdf">[pdf]</a> <a href="https://github.com/tdmeeste/SparseSeqModels">[code]</a></p>
                                <p>Proposes models with predefined sparseness in embeddings and recurrent layers.</p>
							</section>
						</div>
						<div class="4u">
							<section class="special box">
                                <div class="image rounded">
                                    <img src="images/recent_work/snapshot_DeepProbLog.png" alt="" />
                                </div>
								<h4>DeepProbLog: <br/>Neural Probabilistic Logic Programming</h4>
                                <p><i>NIPS 2018</i></p>
                                <p><a href="https://arxiv.org/abs/1805.10872">[pdf]</a></p>
								<p>Presents techniques for combining neural networks and probabilistic logic programs.</p>
							</section>
						</div>
						<div class="4u">
							<section class="special box">
                                <div class="image rounded">
                                    <img src="images/recent_work/snapshot_ExplainingChar.png" alt="" />
                                </div>
								<h4>Explaining Character-Aware Neural Networks <br/>for Word-Level Prediction:<br/>Do They Discover Linguistic Rules?</h4>
                                <p>EMNLP 2018</p>
								<p><a href="https://arxiv.org/pdf/1808.09551.pdf">[pdf]</a> <a href="https://github.com/FredericGodin/ContextualDecomposition-NLP">[code]</a></p>
								<p>Introduces Contextual Decomposition for CNNs and investigates how BiLSTM/CNN models capture morphological rules.</p>
							</section>
						</div>
					</div>
				</div>
			</section>


